\documentclass[12pt,oneside]{book}
\usepackage[utf8]{inputenc}

\usepackage{fancyhdr}           % For page number in the upper right
                                % (required) and other running headers
                                % (optional)
\usepackage{setspace}           % For double-spacing (required)
\usepackage{titlesec}           % For keeping section/\chapter titles
                                % single-spaced

\usepackage{blindtext}          % For generating dummy text in the sample
                                % output, can be removed

% Header height (to avoid fancyhdr error)
\setlength{\headheight}{13.6pt}

% Header formatting for regular pages
\fancyhf{}
\fancyhead[L]{\it\small\leftmark}
\fancyhead[R]{\small\thepage}

% Header formatting for \chapter title pages
\fancypagestyle{plain}{%
  \fancyhf{}
  \fancyhead[R]{\small\thepage}
  \renewcommand{\headrulewidth}{0pt}
}

% Formatting of \chapter and section titles: keep them single-spaced in the
% midst of double-spaced text
\titleformat{\chapter}[display]%
{\bfseries\singlespacing\Large}%
{Chapter~\thechapter}%
{1em}%
{\LARGE}

\titleformat{\section}[hang]%
{\bfseries\singlespacing\Large}%
{\thesection}%
{0.25in}%
{}

\titleformat{\subsection}[hang]%
{\bfseries\singlespacing\large}%
{\thesubsection}%
{0.25in}%
{}

\usepackage{listing}
\usepackage{minted}
\usepackage{xspace}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\rustname}{{\texttt{Rust}}}
\def \rust {\rustname{}\xspace}
\newcommand{\rustcname}{{\texttt{rustc}}}
\def \rustc {\rustcname{}\xspace}
\newcommand{\cname}{{\texttt{C}}}
\def \c {\cname{}\xspace}
\newcommand{\cppname}{{\texttt{C++}}}
\def \cpp {\cppname{}\xspace}
\newcommand{\mirname}{{\texttt{MIR}}}
\def \mir {\mirname{}\xspace}
\newcommand{\hirname}{{\texttt{HIR}}}
\def \hir {\hirname{}\xspace}
\newcommand{\llvmname}{{\texttt{LLVM}}}
\def \llvm {\llvmname{}\xspace}
\newcommand{\llvmirname}{{\texttt{LLVMIR}}}
\def \llvmir {\llvmirname{}\xspace}
\newcommand{\mlname}{{\texttt{ML}}}
\def \ml {\mlname{}\xspace}
\newcommand{\vecname}{{\texttt{Vec}}}
\def \vec{\vecname{}\xspace}
\newcommand{\projectname}{{\texttt{STOUT}}}
\def \name{\projectname\xspace}

\begin{document}
\title{\name: Safe Structure Splitting in a General Purpose Language}
\author{Jacob Bisnett}
\maketitle
\pagestyle{fancy}
\pagenumbering{arabic}
\chapter{Introduction}
\doublespacing
\label{sec:intro}

The programming language \rust is fairly new, but already gained a considerable
following due to its placement as a safe and easy to use alternative to \c and
\cpp. \rust's primary advantage is its robust compile time checks and type
system. Among many of these are:
preventing two mutable references to an object from existing at the same time, 
statically determining when to free objects without reference counting or
garbage collection,
and not allowing references to outlive their objects.

Taken all together, \rust helps the user avoid data races and memory safety
errors by preventing programs that could contain them from compiling.
\rust does allow users to circumvent these rules with ``unsafe'' code,
but this unsafety must be explicitly declared and thus dangerous behavior can be
isolated.

While \rust is not the only language that provides this level of safety, it is
the only popular language that provides this level of safety with little to no overhead,
making it potentially as fast as \c and \cpp while avoiding many of the
pitfalls of the two languages.

\begin{listing}
  \centering
\begin{tabular}{r|c|c}
  Test&Rust&C\\
  k-nucleotide&5.30&6.46\\
  pidigits&1.75&1.73\\
  spectral-norm&2.01&1.98\\
  reverse-complement&0.45&0.42\\
  fasta&1.49&1.32\\
  mandelbrot&1.90&1.64\\
  n-body&13.08&9.56\\
  regex-redux&3.28&1.89\\
  binary-trees&4.27&2.39\\
\end{tabular}

  These numbers are taken from a series of microbenchmarks that attempt to 
  test idiomatic usages of the languages, and thus can be viewed as a comparison
  between how fast languages perform when used naturally.\cite{bench}
  \caption{Rust vs C Microbenchmarks}
  \label{fig:bench}
\end{listing}

Important in that last statement was the fact that \rust has the 
\textit{potential}
to be as fast as \c, and while it performs in the same order of magnitude, its not
quite as fast in many cases, as seen in Figure \ref{fig:bench}.
A potential reason this is that \rust doesn't have the compiler maturity \c has.

The exciting part about the future of \rust is not just that it will eventually
reach parity with \c, but that it could eventually go beyond it. There are
already a few \rust specific optimizations that \c and \cpp cannot do, but that
set is far too small to provide significant gains as of yet.

One significant addition, an addition which is the primary subject of this
paper, would be to allow for the primary \rust compiler, \rustc, to split
structures in ways that maximize cache performance through access locality.

Most modern caches have cache lines that are 64 bytes long. Since accesses from
memory are so expensive it is important that as much useful data is in that 64
bytes as possible. When iterating over some array of integers or floating point
numbers each memory access will result in cache lines that contain mostly
interesting data. However, when iterating over some array of structures,
the mostly useful only
if every field of said structure is accessed at the same time. If only part of
the structure is accessed then the remaining fields are just taking up space in
the cache.

A solution to this problem is splitting the structure into several component
parts. Thus, assuming the structure is split such that fields that are accessed
together are together, cache performance should improve since more useful 
information can fit on each line.

Performing this optimization, however, requires some work. Firstly one
needs to decide which fields should go into
each substructure. This is not a trivial problem, but thankfully a decent
solution has been found\cite{Zhong:2004:ARS:996893.996872}.
Essentially running a program one and collecting
a memory trace one can generate a fairly good estimate of which fields are more
often accessed together by measuring reuse distances and 
thus generate a splitting which, while not provably optimal, 
does manage to successfully split structures and
provide locality benefit.

While the authors created a great system for automating the structure splitting 
process they did not find a great way of using said split structures. They did
use the system in a small research compiler for \c, but it was severely limited
by the fact that they had to limit their compiler to a subset of \c programs
which had a fully static type system, had a decent amount of run time overhead, 
and would not have worked in parallel programs without significant work.

\c isn't the only language which has problems with structure splitting
however. It only makes sense for languages whose structures are contiguous
in memory in the first place, preventing languages such as \texttt{Haskell}.
from implementing it.  Additionally,\texttt{Java} and 
other language with inheritance also
have issues, specifically when dealing with class hierarchies. Structure
splitting would be limited to one class in each class hierarchy. This would
make automated splitting a much more difficult problem, as well as 
make user-defined splitting potentially more confusing.

Given that structure splitting only can work well in a language with
a strongly static type system with contiguous structures and no inheritance,
it seems that \rust is one of the few general purpose languages in which
it would be possible to implement proper structure splitting.

\section{\rustc}
\label{sec:rustc}

\rustc is the most often used, and essentially only, compiler for \rust.
\rustc is effectively a series of conversions from
\rust code to various internal representations and finally into machine code.
First is tokenizes and converts to an \texttt{AST}, then converts that into a
second \texttt{AST}, called \hir. Before April of 2016, when \mir was created,
\hir was the only
internal representation in which serious semantic analysis was performed, which
is likely part of the reason why very little \rust specific optimizations had
been attempted, since \texttt{AST}'s are typically not suited for serious
optimization work. Instead, optimizations were delegated to \llvmir, which \hir
was translated into.

However, the translation from \hir to \llvmir was a long and complicated process.
Much of the semantics of \rust were encoded in the process. To make this 
process easier, a second internal representation was created, called \mir.	


\subsection{\mir}
\mir is fairly new; it was released in April 2016\cite{mirintro}. It acts as a
intermediary between the second of \rust's AST representations, known as \hir,
and \llvmir.

%this is sort of relevant since it saves on some work I discuss later. Might remove
\mir is a fairly standard intermediate representation. \mir represents functions, 
or function-like units like static blocks and closures, 
as a set of basic blocks. Basic blocks are composed of a series of statements
and end in some sort of terminator, of which there are several types. 
Function calls can only be made as part of a terminator. This is
so it can be known statically that every statement of a basic block will
execute\footnote{This isn't strictly true since inline assembly is evaluated as
  a statement, but inline assembly can only be used during unsafe blocks
  anyways, so its not usually relevant}.

  Since \mir is so new, it fairly easy to verify that structure splitting has
  not been successfully implemented in the language\footnote{In fact, field
  reordering has only recently been implemented, meaning its even less
  likely it has been attempted before\todo{Find a citation for this}}

\chapter{Design}

\name (STructure-splitting Optimizations for rUsT) is a structure 
splitting compiler modification that attempts to fix the issues with
previous approaches by implementing structure splitting 
mechanism in \rustc, where static type
safety and general memory safety allow for 
structure splitting with little effect on program
semantics
\footnote{Exactly what effect it has is discussed in the next section and section \ref{sec:limits}}.

\name can be roughly separated into 
four parts, 
structure splitting, 
variable declaration splitting,
variable declaration modification,
and 
\mir assignment modification.

\section{Structure Splitting}

\begin{listing}[h]
\begin{minted}{rust}
//This annotation...
#[affinity_groups(a = 1, b = 2, c = 1)]
struct S {
  pub a: usize,
  pub b: usize,
  pub c: usize,
}

//...results in the following structures
struct S1 {
  pub a: usize,
  pub c: usize,
}
struct S2 {
  pub b: usize,
}
\end{minted}
  \caption{Structure Splitting as a macro}
  \label{fig:split}
\end{listing}

Splitting \rust structures is the simplest part of the process. It is currently
implemented as part of the \rust macro system, where the user of \name
would add an annotation which generates a number
of substructures, each of which contains some subset of it's parent's 
fields. Which fields go in which substructures is decided by arguments 
in the annotations 
this means
that users would need to specify manually how the split the structure. While an
automated solution is of course possible, it is important for a few reasons that
the process be manual, at least at the moment. An example of this
is in \ref{fig:split}

\todo[inline]{I don't like this section}
Firstly it is mandatory that the strategy used 
for structure splitting be modifiable by the user.
Since the structure splitting operation is so global 
and such a potential performance improvement,
some small change could end up resulting in 
massive performance gains or losses. Since it is impossible
to come up with a $100\%$ correct automated strategy, 
allowing a manual override is important, or else
user could potentially prevented from making changes to their code
since it could break the optimization.

\todo[inline]{I don't like this section}
Secondly, deciding how to split a structure is already a solved problem,
but the process is rather expensive. 
It seems like a better idea to just 
allow the user to either; one, 
intelligently reason about there program and split their structure 
how it makes the most sense, or two, 
let them build an already existing tracing solution into their build system
, and thus get the advantage
of deciding when and where to spend the computation time.

\todo[inline]{I don't like this section}
Thirdly, it is important that structure splitting be an ``opt-in'' process.
While \rust is by default a memory safe language, it has an
unsafety system in which memory layout of structures could theoretically matter.
Reasoning about unsafety is currently very difficult in \mir, as
which regions of code are unsafe is not preserved from the transition
form \hir.

\section{Declaration Modification}
In order to properly preserve locality gains, certain declarations
we could not otherwise split need to be modified, otherwise we would need
to write back all our split structures into an original structure to
do anything interesting.

One place we unconditionally perform in place modification is in function
arguments. Any time we are in a function that takes in some splittable
argument \texttt{S}, we want to modify the function to take 
in a tuplified version of \texttt{S}, \texttt{(S1, S2, ...)}. 
We tuplify here as primarily a simplification measure, since 
we could equivalently take more arguments, but currently
\mir makes this process difficult and
not tuplifying does make it possible to accidentally make a function
take in more arguments then \rustc allows.
We also tuplify function pointers to ensure our program typechecks.

Another place we do in place modification is as part of tuples. If we have some
tuple which contains a splittable structure we replace the type of that
structure with a tuple containing the substructures of that structure, as 
in Figure \ref{fig:tupletuplify}.

\begin{figure*}[h]
  \begin{minipage}[t]{0.5\linewidth}
\begin{listing*}
// This declaration...
let \_1: (&S, int, int);
\end{listing*}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{listing*}
// ... turns into this

let \_1: ((&S1, &S2, ...), int, int);
\end{listing*}
  \end{minipage}
  \caption{Tuple Modification}
  \label{fig:tupletuplify}
\end{figure*}

We must do tuplification in type parameters to other structures,
as in Figure \ref{fig:localdeclbefore}.
In most cases this guarentees that we can pass tuplified versions 
of our structures in as
arguments into that other structure's methods, though there are exceptions
discussed in... \todo{write this section, trait impls}

\paragraph{Tuplification and Locality}
In general tuplification
doesn't improve locality, and is effectively equivalent to 
field reordering\footnote{In fact this could make locality worse since each
structure would need to be aligned properly, making the tuple possibly
bigger then the sum of it's parts.}. However it does help us preserve locality.
When we tuplify we keep references bound to the substructures, not the
tuple itself, meaning that we take \texttt{\&S} and convert it into 
\texttt{(\&S1, \&S2, ...)}. This keeps the original location of our 
substructure intact, thus preserving locality benefits.

\begin{listing*}[p]
  \begin{minipage}[t]{0.5\linewidth}
\begin{listing}
// For some structure 
// parameterized by T
let \_1: T<S>;
\end{listing}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{listing}

let \_1: T<(S1, S2, S3>;
\end{listing}
  \end{minipage}
  \caption{Structure Argument Splitting}
  \label{fig:localdeclbefore}
\end{listing*}

%\begin{listing*}
  %\begin{minipage}[t]{0.5\linewidth}
%\begin{minted}{rust}
%// simple case
%let _1: S;
%\end{minted}
  %\end{minipage}
  %\begin{minipage}[t]{0.5\linewidth}
%\begin{minted}{rust}

%let _1: S1;
%let _2: S2;
%let _3: S3;

%\end{minted}
  %\end{minipage}
  
  %\caption{Reference and Array Splitting $g = 3$}
  %\label{fig:localdeclbefore}
%\end{listing*}
\begin{listing*}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// Before splitting
let _1: &S;
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// After splitting.
let _1: &S1;
let _2: &S2;
\end{minted}
  \end{minipage}
  \caption{Reference Splitting}
  \label{fig:refedecl}
\end{listing*}

\section{Splitting}
\label{sec:splitting}

Splitting variable declarations is important since it is where
we get our locality benefits. Unfortunately it is also the trickiest
to get right. 

The simplest case is the one in which
we find a declaration whose type is one of our split structures. In this 
case we can split fairly easily, replacing the declaration of the structure with
declarations for each substructure.
\footnote{This isn't exactly how it works in the code,
instead of \textit{replacing} the declaration we simply add the substructure declarations.
This makes the code simpler, but the detail is largely irrelavent to the
idea, and thus examples will all assume the original declaration is removed.
It is removed when the translation to \llvmir is completed anyway.}

Reference are also easy. If we see a variable that is reference to a structure 
that we can split, we just split that variable into a number of references, 
one for each substructure, as in Figure \ref{fig:refedecl}.

However, even the simple cases have issues. \name cannot split 
a structure \texttt{S} if a use of \texttt{S} does not
allow for \texttt{S} to be split, which is possible in many cases. 
Determining if
\texttt{S} can be split does then depend on a large number of factors.

Splitting just \texttt{S} also rarely results in locality improvements,
as locality benefits are only realized on large sets of data, and 
iterating over large sets of data is most often done with some 
form of array.

\subsection{Array-likes}

Splitting array-like types such as 
arrays, slices, and vectors is where things start
to get tricky. All of those containers have many useful methods
provided to them. Some of them, like indexing operations 
and \texttt{Vec::push()}, can be duplicated across split declarations
while preserving semantic equivalence. However, a large portion of them
cannot be duplicated without incurring run time cost. How we determine which
functions are safe and which are not is discussed in \todo{write this section}.

We can only split arrays-likes if they cannot possibly
break some part of the code. This is fairly simple to verify
in a single function using basic def-use techniques, but
if some array-like value is used in a function call or as 
a return value ensuring semantic equivalence is difficult.

One solution to this problem is
to not split any array-like which escapes the current function.
With aggressive function inlining this \todo{get data on this} could
still provide significant improvement.

A different solution is to also perform recursive checks to see 
if the function to which the array-like is going could possibly
put it in a situation which violates semantic equivalence. If 
so, do not split. This is undoubtable better, but could end up 
taking significant compiler time, and thus is not implemented. 
\todo{Actually check to see if this would take too long}

\subsection{Iterators}
There is a specific set of operations which are not trivially duplicatable
where we can preserve semantic correctness, however. 
Function that return a simple iterator, such as 
\texttt{into\_iter()} and \texttt{iter\_mut()}, can be duplicated correctly
if the resulting iterators are zipped together. 
Zipping is an operation whereby
two iterators of type \texttt{Iterator<A>} and \texttt{Iterator<B>}
are turned into a single iterator of type \texttt{Iterator<(A,B)>}
Because iterators in \rust are lazy, zipping iterators together incurs 
little run time cost.

This does assume that transforming an iterator of type \texttt{Iterator<S>}
into an iterator of type \texttt{Iterator<(S1, S2, ...)>} won't break 
some part of the code. This can be solved by only allowing iterators to 
split if the iterator stays inside the current function an

Not all iterators methods can be safely duplicated in that way however. 
Some return special iterators whose semantics are not necissarily
the same as the basic iteration functions. The semantics could be 
reconstructed in some cases, but not simply by a zip. Additionally,
any iterator that escaped where the compiler can reason about it
can't be zipped. 

Iterators also have some methods in where 
\texttt{Iterator<S>} does not necissarily behave the same as 
\texttt{Iterator<(S1, S2, ...)>}, and when that is the case the iterator
cannot be duplicated and zipped.

\section{Assignment Modification}
\label{sec:assign}

Now that we have properly typed variables, we need to replace the assignments
in each basic block in order to properly use them. The only time we need
to actually replace an assignment is when it involves a variable which was
split

\section{Function Call Modification}
\label{sec:func}


\section{Assumptions}
There are certain assumptions we must make in order for our pass to 
preserve semantic correctness. The first is that all unsafe code that 
could lead a program which is not strictly typesafe is undefined and thus
can be ignored.

\chapter{Preliminary Results}
\section{Limitations}
\label{sec:limits}
Currently \name does not support nesting split structures inside other structures.
This is completely feasible, but requires some fairly extensive compiler
modifications in order to work correctly. Many use cases for this functionality
could switch to a tuple based approach.

\name also doesn't support exporting split structures outside of the current crate.
This is because the compiler cannot easily access code out of the crate, and
thus cannot modify function definitions to accept the tuple of structures we
pass in. This problem could be solved by a few methods, all of which require
either significant compiler modification or the introduction of run
time cost. 

\todo{Should do this}
\name doesn't split static assignments, primarily since writing to a static
assignment at run time is discouraged.

\chapter{Discussion}
\label{sec:discuss}

This project is very much more of a platform for further research then a
standalone project. At the time of writing simple structure splitting
with arrays and references is all that is completed, and 
while I was successful is performing locality based
optimizations in that specific case without the usual run time overhead typical of structure splitting
work, there is considerably more work to be done until I would consider this
a project that should be usable by the average user.

\todo[inline]{Talk about applications on locks}
\todo[inline]{Maybe talk about why not \llvm }

\section{Rust Culture}
\label{sec:culture}

Rust has no good
formal specification. The specification for \mir are practically non-existent. %https://github.com/rust-specification/english-specification
The closest thing there is are an RFC proposing \mir, and a blog post announcing
it, neither of which specify exactly what it can do, and both of which are now
out of date with the current implementation.

Thus, until \mir stablizes and \rust gets an official standard, it is impossible
to truly know if this approach will work on all platforms in all cases. As of 

\chapter{Issues}

While in common cases this approach works very well, there are a few issues with
it, most of which resulting from the fact that Rust does not have a languages
standard. As such, it is difficult to be certain that the compiler pass will
have no semantic effect on the code. It works within the current Rust
implementation, but manual testing can only be so successful.
% possibly cite the commit hash?


\section{Unsafety}
\label{sec:unsafe}


Another major issue is that, because there is no language standard, there is no
good way of dealing with unsafe code. Unsafe code allows for raw pointer
arithmetic, which breaks structure splitting. Rust does have the benefit that
unsafe code must be contained in explicitly declared code blocks.

\chapter{Research Platform}

While \name is complete and functional in itself, it opens the door for 
a good deal more research to occur in this domain. Increasing the automation
of the process is definitely important regardless of my hesitence to automate
the structure splitting process. Of considerable importance is also
the ability to decide which structures can be considered containers and thus 
can be split completely as opposed to just tuplified.


% \chapter{Notes}
% \label{sec:remove}

% \section{Justification}
% \label{sec:just}

% \paragraph{Premonomorphization} Helpful for several reasons
% \begin{enumerate}
% \item Could lower compilation time by not having to regenerate code
% \item  Easier to process in our particular case
% \end{enumerate}

% \paragraph{Shorter Compilation Times} One of the biggest sticking points for
% Rust is that compilation times are quite long, in part due to LLVM taking
% significant time in the compilation process (citation needed). Rust's safety
% could potentially allow for excellent incremental compilation down to the basic
% block level (citation needed). Additionally, LLVM takes a significant part of
% Rust compilation times, and moving some optimization up from LLVM to Rust means
% that other, faster backends can become for feasible. LLVM is also not
% necissarily the best at compiling for certain architectures, such as WebASM.
% With Rust getting WebASM as an alternate backend at some point, developing Rust
% specific optimizations could be good.

% %https://github.com/rust-lang/rust/issues/33205

% \section{Rvalue Type induction}
% Need to update the \texttt{AggregateKind::Array} so that it references the right Ty

% \chapter{Challenges}
% \label{sec:annoying}

% \section{Deriving}
% Most seem to be ok, but some combinations of derivations make things really
% annoying, ie \texttt{Copy} and \texttt{Clone}.

% \section{Polymorphism}

\bibliography{main}{}
\bibliographystyle{acm}
\end{document}
%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: pdflatex
%%% TeX-master: t
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
