\documentclass[12pt,oneside]{book}
\usepackage[utf8]{inputenc}

\usepackage{fancyhdr}           % For page number in the upper right
                                % (required) and other running headers
                                % (optional)
\usepackage{setspace}           % For double-spacing (required)
\usepackage{titlesec}           % For keeping section/\chapter titles
                                % single-spaced

\usepackage{blindtext}          % For generating dummy text in the sample
                                % output, can be removed

% Header height (to avoid fancyhdr error)
\setlength{\headheight}{13.6pt}

% Header formatting for regular pages
\fancyhf{}
\fancyhead[L]{\it\small\leftmark}
\fancyhead[R]{\small\thepage}

% Header formatting for \chapter title pages
\fancypagestyle{plain}{%
  \fancyhf{}
  \fancyhead[R]{\small\thepage}
  \renewcommand{\headrulewidth}{0pt}
}

% Formatting of \chapter and section titles: keep them single-spaced in the
% midst of double-spaced text
\titleformat{\chapter}[display]%
{\bfseries\singlespacing\Large}%
{Chapter~\thechapter}%
{1em}%
{\LARGE}

\titleformat{\section}[hang]%
{\bfseries\singlespacing\Large}%
{\thesection}%
{0.25in}%
{}

\titleformat{\subsection}[hang]%
{\bfseries\singlespacing\large}%
{\thesubsection}%
{0.25in}%
{}

\usepackage{listing}
\usepackage{minted}
\usepackage{xspace}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\rustname}{{\texttt{Rust}}}
\def \rust {\rustname{}\xspace}
\newcommand{\rustcname}{{\texttt{rustc}}}
\def \rustc {\rustcname{}\xspace}
\newcommand{\cname}{{\texttt{C}}}
\def \c {\cname{}\xspace}
\newcommand{\cppname}{{\texttt{C++}}}
\def \cpp {\cppname{}\xspace}
\newcommand{\mirname}{{\texttt{MIR}}}
\def \mir {\mirname{}\xspace}
\newcommand{\hirname}{{\texttt{HIR}}}
\def \hir {\hirname{}\xspace}
\newcommand{\llvmname}{{\texttt{LLVM}}}
\def \llvm {\llvmname{}\xspace}
\newcommand{\llvmirname}{{\texttt{LLVMIR}}}
\def \llvmir {\llvmirname{}\xspace}
\newcommand{\mlname}{{\texttt{ML}}}
\def \ml {\mlname{}\xspace}
\newcommand{\vecname}{{\texttt{Vec}}}
\def \vec{\vecname{}\xspace}
\newcommand{\projectname}{{\texttt{STOUT}}}
\def \name{\projectname\xspace}

\begin{document}
\title{\name: Safe Structure Splitting in a General Purpose Language}
\author{Jacob Bisnett}
\maketitle
\pagestyle{fancy}
\pagenumbering{arabic}
\chapter{Introduction}
\doublespacing
\label{sec:intro}

The programming language \rust is fairly new, but already gained a considerable
following due to its placement as a safe and easy to use alternative to \c and
\cpp. \rust's primary advantage is its robust compile time checks and type
system. Among many of these are:
preventing two mutable references to an object from existing at the same time, 
statically determining when to free objects without reference counting or
garbage collection,
and not allowing references to outlive their objects.

Taken all together, \rust helps the user avoid data races and memory safety
errors by preventing programs that could contain them from compiling.
\rust does allow users to circumvent these rules with ``unsafe'' code,
but this unsafety must be explicitly declared and thus dangerous behavior can be
isolated.

While \rust is not the only language that provides this level of safety, it is
the only popular language that provides this level of safety with little to no overhead,
making it potentially as fast as \c and \cpp while avoiding many of the
pitfalls of the two languages.

\begin{figure}
  \centering
\begin{tabular}{r|c|c}
  Test&Rust&C\\
  k-nucleotide&5.30&6.46\\
  pidigits&1.75&1.73\\
  spectral-norm&2.01&1.98\\
  reverse-complement&0.45&0.42\\
  fasta&1.49&1.32\\
  mandelbrot&1.90&1.64\\
  n-body&13.08&9.56\\
  regex-redux&3.28&1.89\\
  binary-trees&4.27&2.39\\
\end{tabular}

  These numbers are taken from a series of microbenchmarks that attempt to 
  test idiomatic usages of the languages, and thus can be viewed as a comparison
  between how fast languages perform when used naturally.\cite{bench}
  \caption{Rust vs C Microbenchmarks}
  \label{fig:bench}
\end{figure}

Important in that last statement was the fact that \rust has the 
\textit{potential}
to be as fast as \c, and while it performs in the same order of magnitude, its not
quite as fast in many cases, as seen in Figure \ref{fig:bench}.
A potential reason this is that \rust doesn't have the compiler maturity \c has.

The exciting part about the future of \rust is not just that it will eventually
reach parity with \c, but that it could eventually go beyond it. There are
already a few \rust specific optimizations that \c and \cpp cannot do, but that
set is far too small to provide significant gains as of yet.

One significant addition, an addition which is the primary subject of this
paper, would be to allow for the primary \rust compiler, \rustc, to split
structures in ways that maximize cache performance through access locality.

Most modern caches have cache lines that are 64 bytes long. Since accesses from
memory are so expensive it is important that as much useful data is in that 64
bytes as possible. When iterating over some array of integers or floating point
numbers each memory access will result in cache lines that contain mostly
interesting data. However, when iterating over some array of structures,
the mostly useful only
if every field of said structure is accessed at the same time. If only part of
the structure is accessed then the remaining fields are just taking up space in
the cache.

A solution to this problem is splitting the structure into several component
parts. Thus, assuming the structure is split such that fields that are accessed
together are together, cache performance should improve since more useful 
information can fit on each line.

Performing this optimization, however, requires some work. Firstly one
needs to decide which fields should go into
each substructure. This is not a trivial problem, but thankfully a decent
solution has been found\cite{Zhong:2004:ARS:996893.996872}.
Essentially running a program one and collecting
a memory trace one can generate a fairly good estimate of which fields are more
often accessed together by measuring reuse distances and 
thus generate a splitting which, while not provably optimal, 
does manage to successfully split structures and
provide locality benefit.

While the authors created a great system for automating the structure splitting 
process they did not find a great way of using said split structures. They did
use the system in a small research compiler for \c, but it was severely limited
by the fact that they had to limit their compiler to a subset of \c programs
which had a fully static type system, had a decent amount of run time overhead, 
and would not have worked in parallel programs without significant work.

\c isn't the only language which has problems with structure splitting
however. It only makes sense for languages whose structures are contiguous
in memory in the first place, preventing languages such as \texttt{Haskell}.
from implementing it.  Additionally,\texttt{Java} and 
other language with inheritance also
have issues, specifically when dealing with class hierarchies. Structure
splitting would be limited to one class in each class hierarchy. This would
make automated splitting a much more difficult problem, as well as 
make user-defined splitting potentially more confusing.

Given that structure splitting only can work well in a language with
a strongly static type system with contiguous structures and no inheritance,
it seems that \rust is one of the few general purpose languages in which
it would be possible to implement proper structure splitting.

\section{\rustc}
\label{sec:rustc}

\rustc is the most often used, and essentially only, compiler for \rust.
\rustc is effectively a series of conversions from
\rust code to various internal representations and finally into machine code.
First is tokenizes and converts to an \texttt{AST}, then converts that into a
second \texttt{AST}, called \hir. Before April of 2016, when \mir was created,
\hir was the only
internal representation in which serious semantic analysis was performed, which
is likely part of the reason why very little \rust specific optimizations had
been attempted, since \texttt{AST}'s are typically not suited for serious
optimization work. Instead, optimizations were delegated to \llvmir, which \hir
was translated into.

However, the translation from \hir to \llvmir was a long and complicated process.
Much of the semantics of \rust were encoded in the process. To make this 
process easier, a second internal representation was created, called \mir.	


\subsection{\mir}
\mir is fairly new; it was released in April 2016\cite{mirintro}. It acts as a
intermediary between the second of \rust's AST representations, known as \hir,
and \llvmir.

%this is sort of relevant since it saves on some work I discuss later. Might remove
\mir is a fairly standard intermediate representation. \mir represents functions, 
or function-like units like static blocks and closures, 
as a set of basic blocks. Basic blocks are composed of a series of statements
and end in some sort of terminator, of which there are several types. 
Function calls can only be made as part of a terminator. This is
so it can be known statically that every statement of a basic block will
execute\footnote{This isn't strictly true since inline assembly is evaluated as
  a statement, but inline assembly can only be used during unsafe blocks
  anyways, so its not usually relevant}.

  Since \mir is so new, it fairly easy to verify that structure splitting has
  not been successfully implemented in the language\footnote{In fact, field
  reordering has only recently been implemented, meaning its even less
  likely it has been attempted before\todo{Find a citation for this}}

\chapter{Design}

\name (STructure-splitting Optimizations for rUsT) is a structure 
splitting compiler modification that attempts to fix the issues with
previous approaches by implementing structure splitting 
mechanism in \rustc, where static type
safety and general memory safety allow for 
structure splitting with little effect on program
semantics
\footnote{Exactly what effect it has is discussed in the next section and section \ref{sec:limits}}.

\name can be roughly separated into five parts, structure splitting, variable
declaration modification, variable splitting, \mir assignment modification, 
and \mir function call modification.

\section{Structure Splitting}

\begin{figure*}
\begin{minted}{rust}
//This annotation...
#[affinity_groups(a = 1, b = 2, c = 1)]
struct S {
  pub a: usize,
  pub b: usize,
  pub c: usize,
}

//...results in the following structures
struct S1 {
  pub a: usize,
  pub c: usize,
}
struct S2 {
  pub b: usize,
}
\end{minted}
  \caption{Structure Splitting as a macro}
  \label{fig:split}
\end{figure*}

Splitting \rust structures is the simplest part of the process. It is currently
implemented as part of the \rust macro system, where the user of \name
would add an annotation which generates a number
of substructures, each of which contains some subset of it's parent's 
fields. Which fields go in which substructures is decided by arguments 
in the annotations 
this means
that users would need to specify manually how the split the structure. While an
automated solution is of course possible, it is important for a few reasons that
the process be manual, at least at the moment. An example of this
is in \ref{fig:split}

Firstly it is mandatory that the strategy used 
for structure splitting be modifiable by the user.
Since the structure splitting operation is so global 
and such a potential performance improvement,
some small change could end up resulting in 
massive performance gains or losses. Since it is impossible
to come up with a $100\%$ correct automated strategy, 
allowing a manual override is important, or else
user could potentially prevented from making changes to their code
since it could break the optimization.

Secondly, deciding how to split a structure is already a solved problem,
but the process is rather expensive. 
It seems like a better idea to just 
allow the user to either; one, 
intelligently reason about there program and split their structure 
how it makes the most sense, or two, 
let them build an already existing tracing solution into their build system
, and thus get the advantage
of deciding when and where to spend the computation time.

Thirdly, it is important that structure splitting be an ``opt-in'' process.
While \rust is by default a memory safe language, it has an
unsafety system in which memory layout of structures could theoretically matter.
Reasoning about unsafety is currently very difficult in \mir, as
which regions of code are unsafe is not preserved from the transition
form \hir.

\section{Declaration Modification}
In order to properly preserve locality gains, certain variables

Variable declarations can take on one of 22 different types, some of which can
be parameterized by other types. Our action when we see a type can be divided
into three cases, no modification, tuplification, and splitting.

\subsection{No Modification}
Some types we do not need to touch. These include primative types such as
integers, floats, and booleans, as well as internal error types, types used in
type inference\footnote{\mir occurs after types inference}, and any
parameterized type that doesn't contain any structure we are interested in.

\subsection{Tuplification}
For types the can contain one of the split structures, we have two primary
options, the first being what we will call tuplification of the type.

Tuplification is when we take one of our structures \texttt{S} and convert it
into a tuple of substructures \texttt{(S1, S2, ..., Sg}. In general this 
doesn't typically improve locality, and is effectively equivalent to 
field reordering\footnote{In fact this could make locality worse since each
structure would need to be aligned properly, making the tuple possibly
bigger then the sum of it's parts.}. However it is important that we do this to
ensure semantic correctness, and it does help use preserve locality,
since we keep the underlying type structure as well as we can meaning that
we can convert a reference to a structure \texttt{\&S} and convert it into 
\texttt{\&S1, \&S2, ..., \&Sg}, which preserves the original location of the 
data as opposed to simply reassigning the fields into a \texttt{\&S}. We do 
this for as many types as we can, such as arrays, pointers, and other similar
structures.

One place we unconditionally perform in place modification is in function
arguments. This is primarily a simplification measure, since its easier to
tuplify the type of function arguments then to extend the signature of the
function. This additionally makes it impossible to accidentally 
give our functions more
arguments then \rust allows\todo{Don't know if this is true}.
Similarly we perform in place tupling in function pointers so that we correctly
call our modified functions.

Another place we do in place modification is as part of tuples. If we have some
tuple which contains a splittable structure we replace the type of that
structure with a tuple containing the substructures of that structure.

One place we usually do tuplification is when our splittable structure
\texttt{S} is a type arguments to a structure of parametric type, as in 
Figure \ref{fig:localdeclbefore}. There are cases in which we \textit{do} 
want to completely split these definitions and those cases will be discussed
in detail in \ref{sec:param}, but in general we want to tuplify in 
order to preserve correct semantics while keeping locality benefits.
\todo{Maybe give a specific example}

\begin{figure*}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// This declaration...
let _1: T<S>;
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// ... turns into this
let _1: T<(S1, S2, S3>;
\end{minted}
  \end{minipage}
  \caption{Simple Local Declarations Splitting $g = 3$}
  \label{fig:localdeclbefore}
\end{figure*}

\begin{figure*}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// simple case
let _1: S;
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}

let _1: S1;
let _2: S2;
let _3: S3;

\end{minted}
  \end{minipage}
  
  \caption{Reference and Array Splitting $g = 3$}
  \label{fig:localdeclbefore}
\end{figure*}
%\begin{figure*}
  %\begin{minipage}[t]{0.5\linewidth}
%\begin{minted}{rust}
%// reference
%let _1: &S;


%// unsized array (slice)
%let _2: [S];


%// sized array
%let _3: [S, 10000];


%// sized array of references
%let _4: [&S, 10000];

%\end{minted}
  %\end{minipage}
  %\begin{minipage}[t]{0.5\linewidth}
%\begin{minted}{rust}

%let _1: &S1;
%let _2: &S2;
%let _3: &S3;

%let _4: [S1];
%let _5: [S2];
%let _6: [S3];

%let _7: [S1, 10000];
%let _8: [S2, 10000];
%let _9: [S3, 10000];

%let _10: [&S1, 10000];
%let _11: [&S2, 10000];
%let _12: [&S3, 10000];
%\end{minted}
  %\end{minipage}
  
  %\caption{Reference and Array Splitting $g = 3$}
  %\label{fig:refedecl}
%\end{figure*}

\section{Splitting}
\label{sec:splitting}

Actually splitting variable declarations is important since it is where
locality benefits actually come in. Unfortunately it is also the trickiest
to get right.

Since we control the 

The simplest case is the one in which
we find a declaration whose type is one of our split structures. In this 
case we can split fairly easily, replacing the declaration of the structure with
declarations for each substructure
\footnote{This isn't exactly how it works in the code,
instead of \textit{replacing} the declaration we simply add the substructure declarations.
This makes the code simpler, but the detail is largely irrelavent to the
idea, and thus examples will all assume the original declaration is removed.
It is removed when the translation to \llvmir is completed anyway.}

References are handled the same as the simple case, so whenever we 
see a reference containing a splittable structure, we split the declaration.
This process holds for any level of nestings. 

\subsection{Arrays}
Splitting arrays, slices, and vectors in \rust is where things start
to get tricky. All of those containers have many useful methods
provided to them. Some of them, like indexing operations 
and \texttt{Vec::push()}, can be duplicated across split declarations
while preserving semantic equivalence. However, a large portion of them
cannot be duplicated without incurring run time cost. How we determine which
functions are safe and which are not is discussed in \ref{sec:safefn}

Since this is the case, we can only split arrays-likes if they cannot possibly
break some part of the code. Reasoning about this inside a function is 
fairly easy, but reasoning as the array-like crosses function boundries 
either as an argument to a function call or as a return value makes
this significantly harder. 

One solution to this problem is
to not split any array which does escape the current function.
This approach works fine with inlined functions, but
does make it less likely that a user of \name would see 
performance improvements out of the box.

Another solution would be check to see if functions perform any of our
blacklisted functions recursively

\subsection{Iterators}
There is a specific set of operations which are not trivially duplicatable
where we can preserve semantic correctness, however. 
Function that return a simple iterator, such as 
\texttt{into\_iter()} and \texttt{iter\_mut()}, can be duplicated correctly
if the resulting iterators are zipped together. 
Zipping is an operation whereby
two iterators of type \texttt{Iterator<A>} and \texttt{Iterator<B>}
are turned into a single iterator of type \texttt{Iterator<(A,B)>}
Because iterators in \rust are lazy, zipping iterators together incurs 
little run time cost.

This does assume that transforming an iterator of type \texttt{Iterator<S>}
into an iterator of type \texttt{Iterator<(S1, S2, ...)>} won't break 
some part of the code. This can be solved by only allowing iterators to 
split if the iterator stays inside the current function an


Arrays, slices, vectors, and iterators have a fairly stable API and 
identifying which function belong in which cases are fairly simple. 
However, if an array or slice is passed as an argument to a function,
or returned from a function, it is difficult to reason about what 
could happen to it. One answer is to not split any declaration which
escapes the scope of the function or calls a problem function, but 
that would make the gains rather minimal. Another approach is discussed 
in Section \ref{sec:functioncalls};

Array and slice functions can be seperated into three cases; those that
are safe to duplicate with no additional \mir modification,
those that are safe to split with some modification, 
and those that are not safe to split
without significant work and run time cost.

For an array containing some splittable structure \texttt{S},
safe functions are those that take in some argument that isn't \texttt{S}.
The functions that do this are either some variant of \texttt{swap}
\footnote{switch two indicies} or some form of indexing. 

One set of functions that require some modification but are correct are
those that return an iterator. Splitting iterators in some way
is very important since they are one of the primary methods of 
iteration in \rust, and thus iteration 
Since iterators in \rust are lazy, ``zipping'' iterators together is
low cost. The \mir modification is 
then to duplicate whatever function generates the iterator, then
zip all those duplicated iterators together into one iterator
\footnote{This does require that the iterator is only duplicated
six or less times, since six is the maximum number of
iterators that can be zipped together}.

Not all iterators methods can be safely duplicated in that way however. 
Some return special iterators whose semantics are not necissarily
the same as the basic iteration functions. The semantics could be 
reconstructed in some cases, but not simply by a zip. Additionally,
any iterator that escaped where the compiler can reason about it
can't be zipped. 

Iterators also have some methods in where 
\texttt{Iterator<S>} does not necissarily behave the same as 
\texttt{Iterator<(S1, S2, ...)>}, and when that is the case the iterator
cannot be duplicated and zipped.

There are many functions that cannot be safely duplicated however.
Any function which returns a ``special'' iterator can't necissarily
be safely duplicated since it could have other functions not preserved 
by the zip.
Functions that cannot be duplicated are those are depend on \texttt{S}
implementing \texttt{Ord}. These

\subsubsection{Structures}
\label{sec:param}
While in the general case we do not split a structure when 
it is parameterized by
a splittable structure, there are cases in 
which we want to split the base structure
instead of just tuplifying the splittable structure. It is very important
that we handle this correctly, since generic structures 
are very common in \rust. The most common,
and thankfully the easiest to deal with, 
is \vec. \vec is the \rust structure analygous
to the \cpp \texttt{std::vector}. 
It is used practically everywhere, so properly handling it
is extremely important. Most of the applications 
we would be targeting would be storing
their structures in a \vec, 
so not handling would result in structure splitting being
rather ineffective.

\todo[inline]{Probably should do something smart with traits}

However, just simply splitting \vec as we do arrays doesn't work
in all cases.

\begin{float}
\begin{minted}{rust}
struct T {
	pub a: usize,
	pub b: usize,
}
#[affinity_groups(a = 1, b = 2)]
struct S {
	pub a: usize,
	pub b: usize,
}

fn foo() {
	let whole = vec![T{a: 1, b: 2}, T{a: 2, b: 1};
	// let split = vec![S{a: 1, b: 2}, S{a: 2, b: 1}];
	let split_1 = vec![S1{a: 1}, S1{a: 2}];
	let split_2 = vec![S2{b: 2}, S2{b: 2}];
	whole.sort_by(|ref t1, ref t2| s1.a < s2.a);
	// split.sort_by(|ref s1, ref s2| s1.a < s2.a);
}
\end{minted}
\caption{Splitting \vec \texttt{sort\_by}}
\end{float}
The current method of handling this is a whitelist of some of the most common containers in the \rust standard library, 
with the ability for users to declare their container as split-friendly.  
Benefits of this will be discussed in Section \ref{sec:discuss}.


\section{Assignment Replacement}
\label{sec:assign}

Now that we have properly typed variables, we need to replace the assignments
in each basic block in order to properly use them. The only time we need
to actually replace an assignment is when it involves a variable which was
split 

\section{Function Call Modification}
\label{sec:func}


\section{Assumptions}
There are certain assumptions we must make in order for our pass to 
preserve semantic correctness. The first is that all unsafe code that 
could lead a program which is not strictly typesafe is undefined and thus
can be ignored.

\chapter{Preliminary Results}
\section{Limitations}
\label{sec:limits}
Currently \name does not support nesting split structures inside other structures.
This is completely feasible, but requires some fairly extensive compiler
modifications in order to work correctly. Many use cases for this functionality
could switch to a tuple based approach.

\name also doesn't support exporting split structures outside of the current crate.
This is because the compiler cannot easily access code out of the crate, and
thus cannot modify function definitions to accept the tuple of structures we
pass in. This problem could be solved by a few methods, all of which require
either significant compiler modification or the introduction of run
time cost. 

\todo{Should do this}
\name doesn't split static assignments, primarily since writing to a static
assignment at run time is discouraged.

\chapter{Discussion}
\label{sec:discuss}

This project is very much more of a platform for further research then a
standalone project. At the time of writing simple structure splitting
with arrays and references is all that is completed, and 
while I was successful is performing locality based
optimizations in that specific case without the usual run time overhead typical of structure splitting
work, there is considerably more work to be done until I would consider this
a project that should be usable by the average user.

\todo[inline]{Talk about applications on locks}
\todo[inline]{Maybe talk about why not \llvm or \texttt{ghc}}

\section{Rust Culture}
\label{sec:culture}

Rust has no good
formal specification. The specification for \mir are practically non-existent. %https://github.com/rust-specification/english-specification
The closest thing there is are an RFC proposing \mir, and a blog post announcing
it, neither of which specify exactly what it can do, and both of which are now
out of date with the current implementation.

Thus, until \mir stablizes and \rust gets an official standard, it is impossible
to truly know if this approach will work on all platforms in all cases. As of 

\chapter{Issues}

While in common cases this approach works very well, there are a few issues with
it, most of which resulting from the fact that Rust does not have a languages
standard. As such, it is difficult to be certain that the compiler pass will
have no semantic effect on the code. It works within the current Rust
implementation, but manual testing can only be so successful.
% possibly cite the commit hash?


\section{Unsafety}
\label{sec:unsafe}


Another major issue is that, because there is no language standard, there is no
good way of dealing with unsafe code. Unsafe code allows for raw pointer
arithmetic, which breaks structure splitting. Rust does have the benefit that
unsafe code must be contained in explicitly declared code blocks.

\chapter{Research Platform}

While \name is complete and functional in itself, it opens the door for 
a good deal more research to occur in this domain. Increasing the automation
of the process is definitely important regardless of my hesitence to automate
the structure splitting process. Of considerable importance is also
the ability to decide which structures can be considered containers and thus 
can be split completely as opposed to just tuplified.


% \chapter{Notes}
% \label{sec:remove}

% \section{Justification}
% \label{sec:just}

% \paragraph{Premonomorphization} Helpful for several reasons
% \begin{enumerate}
% \item Could lower compilation time by not having to regenerate code
% \item  Easier to process in our particular case
% \end{enumerate}

% \paragraph{Shorter Compilation Times} One of the biggest sticking points for
% Rust is that compilation times are quite long, in part due to LLVM taking
% significant time in the compilation process (citation needed). Rust's safety
% could potentially allow for excellent incremental compilation down to the basic
% block level (citation needed). Additionally, LLVM takes a significant part of
% Rust compilation times, and moving some optimization up from LLVM to Rust means
% that other, faster backends can become for feasible. LLVM is also not
% necissarily the best at compiling for certain architectures, such as WebASM.
% With Rust getting WebASM as an alternate backend at some point, developing Rust
% specific optimizations could be good.

% %https://github.com/rust-lang/rust/issues/33205

% \section{Rvalue Type induction}
% Need to update the \texttt{AggregateKind::Array} so that it references the right Ty

% \chapter{Challenges}
% \label{sec:annoying}

% \section{Deriving}
% Most seem to be ok, but some combinations of derivations make things really
% annoying, ie \texttt{Copy} and \texttt{Clone}.

% \section{Polymorphism}

\bibliography{main}{}
\bibliographystyle{acm}
\end{document}
%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: pdflatex
%%% TeX-master: t
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
