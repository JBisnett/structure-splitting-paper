\documentclass[12pt,final]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{listing}
\usepackage{minted}
\usepackage{xspace}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\rustname}{{\texttt{Rust}}}
\def \rust {\rustname{}\xspace}
\newcommand{\rustcname}{{\texttt{rustc}}}
\def \rustc {\rustcname{}\xspace}
\newcommand{\cname}{{\texttt{C}}}
\def \c {\cname{}\xspace}
\newcommand{\cppname}{{\texttt{C++}}}
\def \cpp {\cppname{}\xspace}
\newcommand{\mirname}{{\texttt{MIR}}}
\def \mir {\mirname{}\xspace}
\newcommand{\hirname}{{\texttt{HIR}}}
\def \hir {\hirname{}\xspace}
\newcommand{\llvmname}{{\texttt{LLVM}}}
\def \llvm {\llvmname{}\xspace}
\newcommand{\llvmirname}{{\texttt{LLVMIR}}}
\def \llvmir {\llvmirname{}\xspace}
\newcommand{\mlname}{{\texttt{ML}}}
\def \ml {\mlname{}\xspace}

\newcommand{\vecname}{{\texttt{Vec}}}
\def \vec {\vecname{}\xspace}

\newcommand{\teststructname}{{\texttt{S}}}
\def \S {\teststructname{}\xspace}

\begin{document}
\title{Locality Optimizing Compiler Transforms in Rust}
\author{Jacob Bisnett}
\maketitle

\section{Introduction}
\label{sec:intro}

The programming language \rust is fairly new, but already gained a considerable
following due to its placement as a safe and easy to use alternative to \c and
\cpp. \rust's primary advantage is its robust compile time checks and type
system. Among many of these are:
preventing two mutable references to an object from existing at the same time, 
statically determining when to free objects without reference counting or
garbage collection,
and not allowing references to outlive their objects.

Taken all together, \rust helps the user avoid data races and memory safety
errors by preventing programs that could contain them from compiling.
\rust does allow users to circumvent these rules with ``unsafe'' code,
but this unsafety must be explicitly declared and thus dangerous behavior can be
isolated.

%maybe list companies using Rust? mozilla, amazon

While \rust is not the only language that provides this level of safety, it is
the only popular language that provides this level of safety with little to no overhead,
making it potentially as fast as \c and \cpp while avoiding many of the
pitfalls of the two languages.

\begin{figure}
  \centering
\begin{tabular}{r|c|c}
  Test&Rust&C\\
  k-nucleotide&5.30&6.46\\
  pidigits&1.75&1.73\\
  spectral-norm&2.01&1.98\\
  reverse-complement&0.45&0.42\\
  fasta&1.49&1.32\\
  mandelbrot&1.90&1.64\\
  n-body&13.08&9.56\\
  regex-redux&3.28&1.89\\
  binary-trees&4.27&2.39\\
\end{tabular}

  These numbers are taken from a series of microbenchmarks that attempt to 
  test idiomatic usages of the languages, and thus can be viewed as a comparison
  between how fast languages perform when used naturally.\cite{bench}
  \caption{Rust vs C Microbenchmarks}
  \label{fig:bench}
\end{figure}

Important in that last statement was the fact that \rust has the \textit{potential}
to be as fast as \c, and while it performs in the same order of magnitude, its not
quite as fast in many cases, as seen in Figure \ref{fig:bench}.
A potential reason this is that \rust doesn't have the compiler maturity \c has.
%citations?

%possibly talk more about this?
The exciting part about the future of \rust is not just that it will eventually
reach parity with \c, but that it could eventually go beyond it. There are
already a few \rust specific optimizations that \c and \cpp cannot do, but that
set is far too small to provide significant gains as of yet.

% FIXME: This may not be true
% However, \rust's newness does have a benefit; it doesn't have a standard yet.
% \rust's lack of a standard means that current compiler writers can be more
% experimental with their compilation passes and still expect them to end up in a
% production compiler.

One significant addition, an addition which is the primary subject of this
paper, would be to allow for the primary \rust compiler, \rustc, to split
structures in ways that maximize cache performance through access locality.

Most modern caches have cache lines that are 64 bytes long. Since accesses from
memory are so expensive it is important that as much useful data is in that 64
bytes as possible. When iterating over some array of integers or floating point
numbers each memory access will result in cache lines that contain mostly
interesting data. However, when iterating over some array of structures,
the mostly useful only
if every field of said structure is accessed at the same time. If only part of
the structure is accessed then the remaining fields are just taking up space in
the cache.

A solution to this problem is splitting the structure into several component
parts. Thus, assuming the structure is split such that fields that are accessed
together are together, cache performance should improve since more useful 
information can fit on each line.

Performing this optimization, however, requires some work. Firstly one
needs to decide where to split the structure, which fields should go in
each substructure. This is not a trivial problem, but thankfully a decent
solution has been found...

\todo[inline]{should explain how structure splitting works in detail}

\subsection{\rustc}
\label{sec:rustc}

\rustc is effectively a series of conversions from
\rust code to various internal representations and finally into machine code.
First is tokenizes and converts to an \texttt{AST}, then converts that into a
second \texttt{AST}, called \hir. Before April of 2016, when \mir was created,
\hir was the only
internal representation in which serious semantic analysis was performed, which
is likely part of the reason why very little \rust specific optimizations had
been attempted, since \texttt{AST}'s are typically not suited for serious
optimization work. Instead, optimizations were delegated to \llvmir, which \hir
was translated into. 
%rust

\subsubsection{\mir}
\mir is fairly new; it was released in April 2016\cite{mirintro}. It acts as a
intermediary between the second of \rust's AST representations, known as \hir,
and \llvmir.

%this is sort of relevant since it saves on some work I discuss later. Might remove
\mir is a fairly standard intermediate representation. It represents functions
as a set of basic blocks. Basic blocks are composed of a series of statements
and end in some sort of terminator, of which there are several types. Important
to know is that function calls can only be made as part of a terminator. This is
so it can be known statically that every statement of a basic block will
execute\footnote{This isn't strictly true since inline assembly is evaluated as
  a statement, but inline assembly can only be used during unsafe blocks
  anyways, so its not usually relevant}.
\todo[inline]{More here}

\section{Structure Splitting in Rust}

My approach to bring structure splitting into \rust was to create a library
containing a macro that performed the actual structure splitting, as well as a
series of \mir passes that performs the changes necessary to use the resulting
split structure.

\subsection{Structure Splitting}

\begin{figure*}
\begin{minted}{rust}
//This annotation...
#[affinity_groups(a = 1, b = 2, c = 1)]
struct S {
  pub a: usize,
  pub b: usize,
  pub c: usize,
}

//...results in the following structures
struct S1 {
  pub a: usize,
  pub c: usize,
}
struct S2 {
  pub b: usize,
}
\end{minted}
  \caption{Structure Splitting as a macro}
  \label{fig:split}
\end{figure*}
Splitting \rust structures is the simplest part of the process. It is currently
implemented as part of the \rust macro system, where the user of my library
would add an annotation, as in Figure \ref{fig:split}, which generates a number
of smaller structures, each of which contains some subset of it's parent's fields.

Currently this means
that users would need to specify manually how the split the structure. While an
automated solution is of course possible, it is important for a few reasons that
the process be manual, at least at the moment. 

Firstly it was mandatory that the strategy used for structure splitting be modifiable by the user.
Since the structure splitting operation is so global and such a potential performance improvement,
some small change could end up resulting in massive performance gains or losses. Since it is impossible
to come up with a $100\%$ correct automated strategy, allowing a manual override is important, or else
user could potentially prevented from making changes to their code
since it could break the optimization.

Secondly, deciding how to split a structure is already a solved problem,
%cite structure splitting
but the process is rather expensive. It seems like a better idea to just allow the user to either; one, 
intelligently reason about there program and split their structure how it makes the most sense, or two, 
let them build an already existing tracing solution into their build system, and thus get the advantage
of deciding when and where to spend the computation time.

Thirdly, it is important that structure splitting be an ``opt-in" process.
While \rust is by default a memory safe language, \rust has an
unsafety system in which memory layout of structures could theoretically matter.
This is less of a problem since usually when reasoning about structure layouts
compiler directive are used to prevent the structure from having strange
layouts, but having an explicit action to activate structure
splitting is important for the default case. 

\todo[inline]{More here}
\subsection{\mir modification}

The majority of my work is a series of \mir passes that actually
implements the structure splitting. While the actual structure splitting should
be in some ways manual, it is vital that the actual splitting logic is
completely automatic, while introducing as little run time cost as possible.

I will explain the process by first assuming that only one structure is getting
split\footnote{Why I limit to one structure is discussed more in Section
\ref{sec:limits}}. I'll call this structure \S. Let us also assume \S has \texttt{n}
fields $\{\texttt{f}_1, \texttt{f}_2, ... \texttt{f}_n\}$
divided into \texttt{g} groups.
Each group then gets their own structure, named \texttt{Sg}.
In order to actually use our split structure we iterate through the set
of variable declarations in each function and determine individually if the
declaration can be split into $g$ declarations. A simple illustrative example is
in Figure \ref{fig:localdeclbefore}

\begin{figure*}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// This declaration...
let _1 = S;
\end{minted}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
\begin{minted}{rust}
// ... turns into this
let _1 = S1;
let _2 = S2;
let _3 = S3;
\end{minted}
  \end{minipage}
  
  \caption{Simple Local Declarations Splitting $g = 3$}
  \label{fig:localdeclbefore}
\end{figure*}

\todo[inline]{Need to fix this paragraph}
Of course deciding whether or not to split a declaration is not a easy as just
checking if it is exactly what we want.  
There are, at time of writing, 22 different kinds of types a variable declaration
can have. For the purposes of this paper, these types can be separated into seven
groups; primitive, internal, reference, arrays, tuples, structures,
and functions.

We can safely ignore primitive and internal types. References, and
arrays are split by recursively checking their internal component and splitting
based on that.

As long as we do not split a tuple with more then one structure, tuples are
also the same. Why we can't split multiple structures in a tuple is discussed in
Section \ref{sec:limits}.

Structures are very easy in the case that the structure is exactly what we are
looking for. Where things get tricky is when some other structure is
parameterized by the structure we are interested in. 

\todo[inline]{Finish this}

\todo[inline]{Talk about functions}

\subsection{Limitations}
\label{sec:limits}
Currently my library does not support nesting split structures inside other structures.
This is completely feasible, but requires some fairly extensive compiler
modifications in order to work correctly. 


\todo{rephrase}
It also do not support splitting more than one structure at a time. This is
partially because it made implementation easier and partially because doing so
could result in some potentially very inefficient code. This is because
splitting multiple structures in tuples could lead to some very, very
inefficient results. Consider the case in which there are $n$ structures split
into $m$ substructures each. If one of each structure was put in an tuple, then
splitting the tuple completely would result in $n^m$\todo{Check this math} total tuples, which can lead
to some serious run time costs, especially if the tuples are parameters to
another type.

\section{Discussion}
\label{sec:discuss}

This project is very much more of a platform for further research then a
standalone project. At the time of writing simple structure splitting
with arrays and references is all that is completed, and 
while I was successful is performing locality based
optimizations in that specific case without the usual run time overhead typical of structure splitting
work, there is considerably more work to be done until I would consider this
a project that should be usable by the average user.

% \begin{figure*}
%  \begin{minted}[autogobble]{rust}
%     struct Mir {
%         basic_blocks: Vec<BasicBlockData>,
%         // ...
%     }

%     struct BasicBlockData {
%         statements: Vec<Statement>,
%         terminator: Terminator,
%         // ...
%     }

%     struct Statement {
%         lvalue: Lvalue,
%         rvalue: Rvalue
%     }

%     enum Terminator {
%         Goto { target: BasicBlock },
%         If {
%             cond: Operand,
%             targets: [BasicBlock; 2]
%         },
%         // ...
%     }
% \end{minted} 
%   \caption{Vec Splitting}
%   \label{fig:vec-split}
% \end{figure*}

The first, and most important, requirement would be to allow for the splitting
of certain types of user defined structures. The first, and most obvious,
benefit for this would be for splitting various containers, the most obvious
being \vec. \vec is the default \rust resizable array class, analagous to \texttt{std::vector}

\todo[inline]{Talk about applications on locks}
\todo[inline]{Maybe talk about why not \llvm or \texttt{ghc}}

\section{Issues}

While in common cases this approach works very well, there are a few issues with
it, most of which resulting from the fact that Rust does not have a languages
standard. As such, it is difficult to be certain that the compiler pass will
have no semantic effect on the code. It works within the current Rust
implementation, but manual testing can only be so successful.
% possibly cite the commit hash?


\subsection{Unsafety}
\label{sec:unsafe}


Another major issue is that, because there is no language standard, there is no
good way of dealing with unsafe code. Unsafe code allows for raw pointer
arithmetic, which breaks structure splitting. Rust does have the benefit that
unsafe code must be contained in explicitly declared code blocks.



% \subsection{Rust Culture}
% \label{sec:culture}

% Rust, as opposed to one of it's parent language's \texttt{Haskell}, has no good
% formal specification. The specification for \mir are practically non-existent. %https://github.com/rust-specification/english-specification
% The closest thing there is are an RFC proposing \mir, and a blog post announcing
% it, neither of which specify exactly what it can do, and both of which are now
% out of date with the current implementation .

% \section{Notes}
% \label{sec:remove}

% \subsection{Justification}
% \label{sec:just}

% \paragraph{Premonomorphization} Helpful for several reasons
% \begin{enumerate}
% \item Could lower compilation time by not having to regenerate code
% \item  Easier to process in our particular case
% \end{enumerate}

% \paragraph{Shorter Compilation Times} One of the biggest sticking points for
% Rust is that compilation times are quite long, in part due to LLVM taking
% significant time in the compilation process (citation needed). Rust's safety
% could potentially allow for excellent incremental compilation down to the basic
% block level (citation needed). Additionally, LLVM takes a significant part of
% Rust compilation times, and moving some optimization up from LLVM to Rust means
% that other, faster backends can become for feasible. LLVM is also not
% necissarily the best at compiling for certain architectures, such as WebASM.
% With Rust getting WebASM as an alternate backend at some point, developing Rust
% specific optimizations could be good.

% %https://github.com/rust-lang/rust/issues/33205

% \subsection{Rvalue Type induction}
% Need to update the \texttt{AggregateKind::Array} so that it references the right Ty

% \section{Challenges}
% \label{sec:annoying}

% \subsection{Deriving}
% Most seem to be ok, but some combinations of derivations make things really
% annoying, ie \texttt{Copy} and \texttt{Clone}.

% \subsection{Polymorphism}

% \subsection{User defined data structures}
% Arrays are fine, but are difficult to use on their own. You really need to
% handle Vectors, and Vectors are... complecated. Basically we needed to define a
% trait, and users need to implement that trait on objects when it is safe to, ie
% when it is stored in a ``dumb'' way, that doesn't semantically depend on the
% contents of the object. This allows for potentially better cache behavior in
% stuff such as HashMaps.

\bibliography{main}{}
\bibliographystyle{acm}
\end{document}